{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, PeftModel, get_peft_config, get_peft_model\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6ca49978b94c1097128f3f0654c5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call model/tokenizer\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    device_map='auto', \n",
    "    torch_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# print(base_model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 200 200\n"
     ]
    }
   ],
   "source": [
    "# call data\n",
    "with open(\"/home/broodling/finQA/post_schemas_0928.json\", \"r\") as f1:\n",
    "  posts = json.load(f1)\n",
    "\n",
    "with open(\"/home/broodling/finQA/pre_schemas_0928.json\", \"r\") as f2:\n",
    "  pres = json.load(f2)\n",
    "\n",
    "with open(\"/home/broodling/finQA/table_schemas_0928.json\", \"r\") as f3:\n",
    "  tables = json.load(f3)\n",
    "\n",
    "with open(\"/home/broodling/finQA/datasets/FinQA/dataset/train.json\", \"r\") as f4:\n",
    "  datas = json.load(f4)\n",
    "\n",
    "\n",
    "questions = []\n",
    "for ques in datas[:200]:\n",
    "  questions.append(ques['qa']['question'])\n",
    "\n",
    "\n",
    "print(len(posts), len(pres), len(tables), len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt engineering\n",
    "sys_prompt = \"\"\"Given the following pair of SQL schema and natual language question, generate a correct SQL query to correctly answer the given question. Considering given schema information, especially column names, generate SQL query that can solve given question and syntactically perfect(must be executed without any errors). \n",
    "Use the following format and ONLY answer in sql query:\n",
    "Question: \"Question\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Given the SQL schema and a natual language question, generate a corresponding SQL query.\n",
    "Schema: {schema}\\n\n",
    "Question: {ques}\n",
    "SQLQuery: \"\"\"\n",
    "\n",
    "## few-shot example (BookSQL)\n",
    "sch1=\"\"\"CREATE TABLE chart_of_accounts(\n",
    "    id INTEGER ,\n",
    "    businessID INTEGER NOT NULL,\n",
    "    Account_name TEXT NOT NULL,\n",
    "    Account_type TEXT NOT NULL,\n",
    ");\n",
    "CREATE TABLE master_txn_table(\n",
    "    id INTEGER ,\n",
    "    businessID INTEGER NOT NULL ,\n",
    "    Transaction_ID INTEGER NOT NULL,\n",
    "    Transaction_DATE DATE NOT NULL,\n",
    "    Transaction_TYPE TEXT NOT NULL,\n",
    "    Amount DOUBLE NOT NULL,\n",
    "    Account TEXT NOT NULL,\n",
    "    Due_DATE DATE,             \n",
    ");\"\"\"\n",
    "user_prompt_1 = template.format(schema=sch1, ques=\"What acount had our biggest expense This week to date?\")\n",
    "assistant_prompt_1 = \"SELECT account, SUM(debit) FROM master_txn_table AS T1 JOIN chart_of_accounts AS T2 ON T1.account = T2.account_name  WHERE account_type IN ('Expense','Other Expense') AND transaction_date BETWEEN date( current_date, \\\"weekday 0\\\", \\\"-7 days\\\") AND date( current_date) GROUP BY account ORDER BY SUM(debit) DESC LIMIT 1\"\n",
    "\n",
    "sch2 = \"\"\"CREATE TABLE student (\n",
    "    student_id INTEGER,\n",
    "    last_name TEXT,\n",
    "    first_name TEXT,\n",
    "    age INTEGER,\n",
    "    sex TEXT,\n",
    "    major INTEGER,\n",
    "    advisor INTEGER, \n",
    "    city_code TEXT, \n",
    ");\n",
    "CREATE TABLE has_pet (\n",
    "    student_id INTEGER,\n",
    "    pet_id INTEGER,\n",
    ");\"\"\"\n",
    "user_prompt_2 = template.format(schema=sch2, ques=\"What is the average age for all students who do not own any pets?\")\n",
    "assistant_prompt_2 = \"SELECT avg(age) FROM student WHERE student_id NOT IN (SELECT T1.student_id FROM student AS T1 JOIN has_pet AS T2 ON T1.student_id = T2.student_id)\"\n",
    "\n",
    "messages =[\n",
    "  {\"role\": \"system\", \"content\": sys_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt_1},\n",
    "  {\"role\": \"assistant\", \"content\": assistant_prompt_1},\n",
    "  {\"role\": \"user\", \"content\": user_prompt_2},\n",
    "  {\"role\": \"assistant\", \"content\": assistant_prompt_2},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre, table, post in zip(pres, tables, posts):\n",
    "  total = pre + table + post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:03,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT interest_expense FROM TableData WHERE date = '2009-01-01'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:03<00:06,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT CASE WHEN SUM(EquityAwards.granted_value) - SUM(EquityAwards.forfeited_value) > PostD.additional_stock_based_compensation_expense THEN 'Yes' ELSE 'No' END \n",
      "FROM EquityAwards \n",
      "JOIN PostD ON EquityAwards.year = PostD.year \n",
      "WHERE EquityAwards.year = 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:04<00:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT total_operating_expenses / 1000000 FROM OperatingExpenses WHERE year = 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:06<00:01,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT CAST(T2.available_for_sale_investments AS REAL) * 100 / T2.total_cash_and_investments FROM TableData AS T2 JOIN PreD AS T1 ON T2.date = T1.date WHERE T1.date = '2012-12-29'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT (net_revenue - (SELECT net_revenue FROM TableData WHERE year = 2007)) / (SELECT net_revenue FROM TableData WHERE year = 2007) * 100 FROM TableData WHERE year = 2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run text2SQL generation (Generate SQL Query) => posts, pres, tables, questions\n",
    "SQLs = []\n",
    "for idx in tqdm(range(0,5)):\n",
    "  total_db = pres[idx] + tables[idx] + posts[idx]\n",
    "  user_prompt = template.format(schema=total_db, ques=questions[idx])\n",
    "  dic = {\"role\": \"user\", \"content\": user_prompt}\n",
    "  messages.append(dic)\n",
    "  # print(dic[\"content\"])\n",
    "\n",
    "  input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "  input_ids = input_ids.to(base_model.device) \n",
    "\n",
    "  output = base_model.generate(input_ids=input_ids,\n",
    "                               max_length = 12500,\n",
    "                               temperature=0.2,\n",
    "                               pad_token_id = tokenizer.eos_token_id)[0]\n",
    "  \n",
    "  response = tokenizer.decode(output)\n",
    "  #print(response)\n",
    "  res = response.split(\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")[3]\n",
    "  res = res.rstrip(\"<|eot_id|>\")\n",
    "  res = res.lstrip(\"\\n\")\n",
    "  # print(res)\n",
    "\n",
    "  SQLs.append(res)\n",
    "  del messages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT T1.net_change FROM UnrecognizedTaxBenefits AS T1 JOIN Skyworks AS T2 ON T1.year = T2.year WHERE T1.year = 2012 AND T2.year = 2011\n",
      "SELECT T1.operating_profit_increase FROM OperatingProfit AS T1 JOIN Aeronautics AS T2 ON T1.year = T2.year WHERE T2.year = 2011\n",
      "SELECT CAST((operating_lease_obligations - LAG(operating_lease_obligations) OVER (ORDER BY year)) / LAG(operating_lease_obligations) OVER (ORDER BY year) * 100 AS DECIMAL(10, 2)) FROM ContractualObligations WHERE year IN (2009, 2010)\n",
      "SELECT CAST(SUM(CASE WHEN T2.country = 'United States' THEN T1.square_feet ELSE 0 END) AS DECIMAL(10, 2)) * 100 / SUM(T1.square_feet) FROM TableData AS T1 JOIN AppliedLocations AS T2 ON T1.location = T2.location_nam\n",
      "SELECT total_return FROM StockReturn WHERE index_name = 'Nasdaq Composite' AND initial_investment = 1000000.00 AND start_date BETWEEN '2009-01-01' AND '2009-12-31' AND end_date BETWEEN '2010-01-01' AND '2010-12-31'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/broodling/finQA/text2sql_0929_200.json\", \"r\") as f:\n",
    "  sqls = json.load(f)\n",
    "\n",
    "for sql in sqls[100:105]:\n",
    "  print(sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
