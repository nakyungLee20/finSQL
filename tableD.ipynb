{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, PeftModel, get_peft_config, get_peft_model\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58f7d8b06cb42e9892435b3ba3a3419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Call basemodel(llama3.1 8B) \n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    device_map='auto', \n",
    "    torch_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6251 6251\n",
      "[['', 'number of shares ( in thousands )', 'weighted average grant date fair value ( per share )'], ['restricted stock and restricted stock units at beginning of year', '407', '$ 9.84'], ['granted', '607', '18.13'], ['vested', '-134 ( 134 )', '10.88'], ['forfeited', '-9 ( 9 )', '13.72'], ['restricted stock and restricted stock units at end of year', '871', '$ 15.76']]\n"
     ]
    }
   ],
   "source": [
    "## preprocess data\n",
    "import json\n",
    "\n",
    "data_pth = \"/home/broodling/finQA/datasets/FinQA/dataset/train.json\"\n",
    "\n",
    "tables_ori = []\n",
    "questions = []\n",
    "\n",
    "with open(data_pth, \"r\") as file:\n",
    "  data = json.load(file)\n",
    "\n",
    "for i in data:\n",
    "  questions.append(i['qa']['question'])\n",
    "  tables_ori.append(i['table'])\n",
    "\n",
    "print(len(tables_ori), len(questions))\n",
    "print(tables_ori[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date 31-dec-2012 of citi is 100.0\n",
      "date 31-dec-2012 of s&p 500 is 100.0\n",
      "date 31-dec-2012 of s&p financials is 100.0\n",
      "date 31-dec-2013 of citi is 131.8\n",
      "date 31-dec-2013 of s&p 500 is 132.4\n",
      "date 31-dec-2013 of s&p financials is 135.6\n",
      "date 31-dec-2014 of citi is 137.0\n",
      "date 31-dec-2014 of s&p 500 is 150.5\n",
      "date 31-dec-2014 of s&p financials is 156.2\n",
      "date 31-dec-2015 of citi is 131.4\n",
      "date 31-dec-2015 of s&p 500 is 152.6\n",
      "date 31-dec-2015 of s&p financials is 153.9\n",
      "date 31-dec-2016 of citi is 152.3\n",
      "date 31-dec-2016 of s&p 500 is 170.8\n",
      "date 31-dec-2016 of s&p financials is 188.9\n",
      "date 31-dec-2017 of citi is 193.5\n",
      "date 31-dec-2017 of s&p 500 is 208.1\n",
      "date 31-dec-2017 of s&p financials is 230.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table_str = []\n",
    "for table in tables_ori:\n",
    "  sen = \"\"\n",
    "  for i in range(1, len(table)):\n",
    "    for j in range(1, len(table[0])):\n",
    "      cell = table[0][0] +\" \" + table[i][0] + \" of \" + table[0][j] + \" is \" + table[i][j] + \"\\n\"\n",
    "      sen += cell\n",
    "  sen = sen.replace(\"  \", \" \")\n",
    "  table_str.append(sen)\n",
    "\n",
    "with open(\"table_string_0928.json\", \"w\") as fw:\n",
    "  json.dump(table_str, fw)\n",
    "\n",
    "exam = [[\n",
    "    \"date\",\n",
    "    \"citi\",\n",
    "    \"s&p 500\",\n",
    "    \"s&p financials\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2012\",\n",
    "    \"100.0\",\n",
    "    \"100.0\",\n",
    "    \"100.0\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2013\",\n",
    "    \"131.8\",\n",
    "    \"132.4\",\n",
    "    \"135.6\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2014\",\n",
    "    \"137.0\",\n",
    "    \"150.5\",\n",
    "    \"156.2\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2015\",\n",
    "    \"131.4\",\n",
    "    \"152.6\",\n",
    "    \"153.9\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2016\",\n",
    "    \"152.3\",\n",
    "    \"170.8\",\n",
    "    \"188.9\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2017\",\n",
    "    \"193.5\",\n",
    "    \"208.1\",\n",
    "    \"230.9\"\n",
    "]]\n",
    "\n",
    "fewshot = \"\"\n",
    "for i in range(1, len(exam)):\n",
    "    for j in range(1, len(exam[0])):\n",
    "        cell = exam[0][0] +\" \" + exam[i][0] + \" of \" + exam[0][j] + \" is \" + exam[i][j] + \"\\n\"\n",
    "        fewshot += cell\n",
    "fewshot = fewshot.replace(\"  \", \" \")\n",
    "print(fewshot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|cell|> <col> year 2018 </col> <row> gallons </row> <val> 4447 </val> <|/cell|> <|cell|> <col> year 2018 </col> <row> average priceper gallon </row> <val> $ 2.23 </val> <|/cell|> <|cell|> <col> year 2018 </col> <row> aircraft fuelexpense </row> <val> $ 9896 </val> <|/cell|> <|cell|> <col> year 2018 </col> <row> percent of totaloperating expenses </row> <val> 23.6% ( 23.6 % ) </val> <|/cell|> <|cell|> <col> year 2017 </col> <row> gallons </row> <val> 4352 </val> <|/cell|> <|cell|> <col> year 2017 </col> <row> average priceper gallon </row> <val> 1.73 </val> <|/cell|> <|cell|> <col> year 2017 </col> <row> aircraft fuelexpense </row> <val> 7510 </val> <|/cell|> <|cell|> <col> year 2017 </col> <row> percent of totaloperating expenses </row> <val> 19.6% ( 19.6 % ) </val> <|/cell|> <|cell|> <col> year 2016 </col> <row> gallons </row> <val> 4347 </val> <|/cell|> <|cell|> <col> year 2016 </col> <row> average priceper gallon </row> <val> 1.42 </val> <|/cell|> <|cell|> <col> year 2016 </col> <row> aircraft fuelexpense </row> <val> 6180 </val> <|/cell|> <|cell|> <col> year 2016 </col> <row> percent of totaloperating expenses </row> <val> 17.6% ( 17.6 % ) </val> <|/cell|> \n",
      "6251\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table_str = []\n",
    "for table in tables_ori:\n",
    "  header=table[0]\n",
    "  sent = \"\"\n",
    "  for col in range(1, len(table)):\n",
    "    for row in range(1, len(table[col])):\n",
    "      sent += \"<|cell|>\" + \" <col> \" + table[0][0] + \" \" + table[col][0] + \" </col> \" + \"<row> \" + table[0][row] + \" </row> \" + \"<val> \" + table[col][row] + \" </val> \" +\"<|/cell|> \"\n",
    "      sent = sent.replace(\"  \", \" \")\n",
    "\n",
    "  # print(sent)\n",
    "  table_str.append(sent)\n",
    "\n",
    "print(table_str[2])\n",
    "print(len(table_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6251\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table_str = []\n",
    "for table in tables_ori:\n",
    "  sen = \"\"\n",
    "  for i in range(1, len(table)):\n",
    "    for j in range(1, len(table[0])):\n",
    "      col = \" <col> \" + table[0][0] +\" \" + table[i][0] + \" \" + table[0][j] +  \" </col>\"\n",
    "      val = \" <val> \" + table[i][j] + \" </val> \"\n",
    "      sen += \"<|cell|>\" + col + val + \"<|/cell|>\\n\"\n",
    "  #print(sen)\n",
    "  table_str.append(sen)\n",
    "\n",
    "print(len(table_str))\n",
    "\n",
    "with open(\"table_string.json\", \"w\") as fw:\n",
    "  json.dump(table_str, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|cell|> <col> date 31-dec-2012 citi </col> <val> 100.0 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2012 s&p 500 </col> <val> 100.0 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2012 s&p financials </col> <val> 100.0 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2013 citi </col> <val> 131.8 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2013 s&p 500 </col> <val> 132.4 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2013 s&p financials </col> <val> 135.6 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2014 citi </col> <val> 137.0 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2014 s&p 500 </col> <val> 150.5 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2014 s&p financials </col> <val> 156.2 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2015 citi </col> <val> 131.4 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2015 s&p 500 </col> <val> 152.6 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2015 s&p financials </col> <val> 153.9 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2016 citi </col> <val> 152.3 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2016 s&p 500 </col> <val> 170.8 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2016 s&p financials </col> <val> 188.9 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2017 citi </col> <val> 193.5 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2017 s&p 500 </col> <val> 208.1 </val> <|/cell|>\n",
      "<|cell|> <col> date 31-dec-2017 s&p financials </col> <val> 230.9 </val> <|/cell|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exam = [[\n",
    "    \"date\",\n",
    "    \"citi\",\n",
    "    \"s&p 500\",\n",
    "    \"s&p financials\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2012\",\n",
    "    \"100.0\",\n",
    "    \"100.0\",\n",
    "    \"100.0\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2013\",\n",
    "    \"131.8\",\n",
    "    \"132.4\",\n",
    "    \"135.6\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2014\",\n",
    "    \"137.0\",\n",
    "    \"150.5\",\n",
    "    \"156.2\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2015\",\n",
    "    \"131.4\",\n",
    "    \"152.6\",\n",
    "    \"153.9\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2016\",\n",
    "    \"152.3\",\n",
    "    \"170.8\",\n",
    "    \"188.9\"\n",
    "],\n",
    "[\n",
    "    \"31-dec-2017\",\n",
    "    \"193.5\",\n",
    "    \"208.1\",\n",
    "    \"230.9\"\n",
    "]]\n",
    "\n",
    "fewshot = \"\"\n",
    "for i in range(1, len(exam)):\n",
    "    for j in range(1, len(exam[0])):\n",
    "        col = \" <col> \" + exam[0][0] +\" \" + exam[i][0] + \" \" + exam[0][j] +  \" </col>\"\n",
    "        val = \" <val> \" + exam[i][j] + \" </val> \"\n",
    "        fewshot += \"<|cell|>\" + col + val + \"<|/cell|>\\n\"\n",
    "\n",
    "print(fewshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prompt for table decomposition\n",
    "sys_prompt = \"\"\"You will receive a text along with a table/query pair. When you receive this pair, you should review the query and extract only necessary information, especially NUMBERS, to solve the query from the table. Then, reconstruct a condensed(summerized) table with the extracted information into a following table format. In table format, each cell starts with <|cell|> token and ends with <|/cell|> tokens. Cell's column information are enclosed by <col>, </col> tokens and value(or number) is enclosed by <val>, </val> tokens. DO NOT provide the equation to solve the problem, just correctly select the relevant columns/values. Skip detailed information and ONLY answer the extracted information with the table format.\"\"\"\n",
    "\n",
    "# provide example (few-shot 1)\n",
    "user_prompt = \"\"\"Query: what was the percentage cumulative total return for the five year period ended 31-dec-2017 of citi common stock?\n",
    "Table: {}\n",
    "Sub-Table: \n",
    "\"\"\".format(fewshot)\n",
    "\n",
    "assistant_prompt = \"\"\"|<cell>| <col> date 31-dec-2012 citi </col> <val> 100.0 </val> |</cell>|\\n |<cell>| <col> date 31-dec-2012 s&p 500 </col> <val> 100.0 </val> |</cell>|\\n <|cell|> <col> date 31-dec-2012 s&p financials </col> <val> 100.0 </val> <|/cell|>\\n <|cell|> <col> date 31-dec-2017 citi </col> <val> 193.5 </val> <|/cell|>\\n <|cell|> <col> date 31-dec-2017 s&p 500 </col> <val> 208.1 </val> <|/cell|>\\n <|cell|> <col> date 31-dec-2017 s&p financials </col> <val> 230.9 </val> <|/cell|>\\n \"\"\"\n",
    "\n",
    "messages =[\n",
    "  {\"role\": \"system\", \"content\": sys_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "  {\"role\": \"assistant\", \"content\": assistant_prompt},\n",
    "]\n",
    "\n",
    "# Move the model to GPU if available, otherwise CPU\n",
    "# if torch.cuda.is_available():\n",
    "#     base_model = base_model.to(\"cuda\")\n",
    "#     print(\"cuda\")\n",
    "\n",
    "# print(base_model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/6251 [00:01<3:06:11,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|<cell>| <col> fair value of forward exchange contracts asset ( liability ) october 31 2009 </col> <val> $ 6427 </val> |</cell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/6251 [00:13<13:17:22,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|<cell>| <col>  restricted stock and restricted stock units at beginning of year number of shares ( in thousands ) </col> <val> 407 </val> |</cell>|\n",
      " |<cell>| <col>  granted number of shares ( in thousands ) </col> <val> 607 </val> |</cell>|\n",
      " |<cell>| <col>  vested number of shares ( in thousands ) </col> <val> -134 ( 134 ) </val> |</cell>|\n",
      " |<cell>| <col>  forfeited number of shares ( in thousands ) </col> <val> -9 ( 9 ) </val> |</cell>|\n",
      " |<cell>| <col>  restricted stock and restricted stock units at end of year number of shares ( in thousands ) </col> <val> 871 </val> |</cell>|\n",
      " |<cell>| <col>  granted weighted average grant date fair value ( per share ) </col> <val> 18.13 </val> |</cell>|\n",
      " |<cell>| <col>  vested weighted average grant date fair value ( per share ) </col> <val> 10.88 </val> |</cell>|\n",
      " |<cell>| <col>  forfeited weighted average grant date fair value ( per share ) </col> <val> 13.72 </val> |</cell>|\n",
      " |<cell>| <col>  restricted stock and restricted stock units at end of year weighted average grant date fair value ( per share ) </col> <val> $ 15.76 </val> |</cell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/6251 [00:15<13:11:31,  7.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(base_model\u001b[38;5;241m.\u001b[39mdevice) \n\u001b[0;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output)\n\u001b[1;32m     17\u001b[0m res \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|><|start_header_id|>assistant<|end_header_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/transformers/generation/utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1986\u001b[0m     )\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1997\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2006\u001b[0m     )\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/transformers/generation/utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1141\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1138\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:944\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    932\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    933\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    934\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    941\u001b[0m         position_embeddings,\n\u001b[1;32m    942\u001b[0m     )\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 944\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:677\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:615\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    613\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 615\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m, past_key_value\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/accelerate/hooks.py:164\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 164\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/accelerate/hooks.py:363\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[1;32m    354\u001b[0m         set_module_tensor_to_device(\n\u001b[1;32m    355\u001b[0m             module,\n\u001b[1;32m    356\u001b[0m             name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m             tied_params_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map,\n\u001b[1;32m    361\u001b[0m         )\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m)\u001b[49m, send_to_device(\n\u001b[1;32m    364\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    365\u001b[0m )\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/accelerate/utils/operations.py:174\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, Mapping):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(skip_keys, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/finQA/venv/lib/python3.11/site-packages/accelerate/utils/operations.py:81\u001b[0m, in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(generator))\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(generator)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "answers = []\n",
    "\n",
    "for idx in tqdm(range(0, len(table_str))):\n",
    "  dic = {\"role\": \"user\", \"content\": \"Query: {} \\nTable: {} \\nSub-Table: \".format(questions[idx], table_str[idx])}\n",
    "  messages.append(dic)\n",
    "  input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "  input_ids = input_ids.to(base_model.device) \n",
    "\n",
    "  output = base_model.generate(input_ids=input_ids,\n",
    "                               max_length = 4096,\n",
    "                               temperature=0.2,\n",
    "                               pad_token_id = tokenizer.eos_token_id)[0]\n",
    "  \n",
    "  response = tokenizer.decode(output)\n",
    "  res = response.split(\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")[2]\n",
    "  res = res.lstrip(\"\\n\")\n",
    "  res = res.rstrip(\"<|eot_id|>\")\n",
    "  # print(res)\n",
    "\n",
    "  answers.append(res)\n",
    "  del messages[-1]\n",
    "\n",
    "\n",
    "## save result\n",
    "with open(\"subtable_0817.json\", \"w\") as f1:\n",
    "  json.dump(answers, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|<cell>| <col> labor-related deemed claim </col> <row> 2013 </row> <val> $ 1733 </val> |</cell>|\n",
      "|<cell>| <col> total reorganization items net </col> <row> 2013 </row> <val> $ 2640 </val> |</cell\n",
      "\n",
      "|<cell>| <col> obligation </col> <row> payments due by period total </row> <val> $ 37788 </val> |</cell>| \n",
      "|<cell>| <col> obligation </col> <row> payments due by period total </row> <val> $ 186792 </val> |</cell\n",
      "\n",
      "|<cell>| <col> ( in millions ) </col> <row> long-term debt including current portion excluding capital lease obligations </row> <row> payments due by period total </row> <val> $ 6039.0 </val> |</cell>|\n",
      "|<cell>| <col> ( in millions ) </col> <row> long-term debt including current portion excluding capital lease obligations </row> <row> payments due by period fiscal 2019 </row> <val> $ 726.6 </val> |</cell\n",
      "\n",
      "|<cell>| <col> <row> owned </row> </col> <col> <row> leased </row> </col> </cell> |\n",
      "|<cell>| <col> <row> united states </row> </col> <val> 41 </val> </cell> |<cell>| <col> <row> united states </row> </col> <val> 1 </val> </cell> |\n",
      "|<cell>| <col> <row> canada </row> </col> <val> 2 </val> </cell> |<cell>| <col> <row> canada </row> </col> <val> 2014 </val> </cell> |\n",
      "|<cell>| <col> <row> europe </row> </col> <val> 11 </val> </cell> |<cell>| <col> <row> europe </row> </col> <val> 2014 </val> </cell> |\n",
      "|<cell>| <col> <row> rest of world </row> </col> <val> 26 </val> </cell> |<cell>| <col> <row> rest of world </row> </col> <val> 2 </val> </cell> \n",
      "\n",
      "|<cell>| <col> ( in millions ) </col> <row> proceeds from Clearwire transactions </row> <val> $  1,600 </val> |</cell>|\n",
      "|<cell>| <col> ( in millions ) </col> <row> gain recognized </row> <val> $  1,600 </val> |</cell>|\n",
      "|<cell>| <col> ( in millions ) </col> <row> equity investments, net </row> <val> $  1038 </val> |</cell\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "answers = [\"0-th as few-shot example\"]\n",
    "\n",
    "for ques, idx in zip(questions[15:20], table_str[15:20]):\n",
    "  dic = {\"role\": \"user\", \"content\": \"Query: {} \\nTable: {} \\nSub-Table: \".format(ques, idx)}\n",
    "  messages.append(dic)\n",
    "  input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "  input_ids = input_ids.to(base_model.device) \n",
    "\n",
    "  output = base_model.generate(input_ids=input_ids,\n",
    "                               max_length = 4096,\n",
    "                               temperature=0.2,\n",
    "                               pad_token_id = tokenizer.eos_token_id)[0]\n",
    "  \n",
    "  response = tokenizer.decode(output)\n",
    "  res = response.split(\"<|start_header_id|>assistant<|end_header_id|>\")[2]\n",
    "  res = res.lstrip(\"\\n\")\n",
    "  res = res.rstrip(\"<|eot_id|>\")\n",
    "  # print(res)\n",
    "\n",
    "  answers.append(res)\n",
    "  del messages[-1]\n",
    "\n",
    "\n",
    "## save result\n",
    "# with open(\"sub_table_0807.json\", \"w\") as f1:\n",
    "#   json.dump(answers, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|<cell>| <col> </col> <row> <total> </row> <val> 41 + 2 + 11 + 26 = 80 </val> |</cell>| \\n|<cell>| <col> </col> <row> <leased> </row> <val> 1 + 2014 + 2014 + 2 = 4031 </val> |</cell>| \\n|<cell>| <col> </col> <row> <percent leased> </row> <val> (4031 / 80) * 100 = 50.38 </val> |</cell'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/home/broodling/finQA/tr_subtable_extract_0807.json\") as file:\n",
    "  test = json.load(file)\n",
    "\n",
    "test[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:05<00:00,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|<cell>| <col> granted </col> <row> number of shares ( in thousands ) </row> <val> 607 </val> |</cell>|\n",
      "|<cell>| <col> granted </col> <row> weighted average grant date fair value ( per share ) </row> <val> $ 18.13 </val> |</cell>|\n",
      "|<cell>| <col> vested </col> <row> number of shares ( in thousands ) </row> <val> -134 ( 134 ) </val> |</cell>|\n",
      "|<cell>| <col> vested </col> <row> weighted average grant date fair value ( per share ) </row> <val> $ 10.88 </val> |</cell>|<|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "answers = []\n",
    "\n",
    "for idx in tqdm(range(1, len(table_str))):\n",
    "  dic = {\"role\": \"user\", \"content\": \"Query: {} \\nTable: {} \\nSub-Table: \".format(questions[idx], table_str[idx])}\n",
    "  messages.append(dic)\n",
    "  input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "  input_ids = input_ids.to(base_model.device) \n",
    "  # print(input_ids.device)\n",
    "\n",
    "  output = base_model.generate(input_ids=input_ids,\n",
    "                               max_length = 4096,\n",
    "                               temperature=0.2,\n",
    "                               pad_token_id = tokenizer.eos_token_id)[0]\n",
    "  \n",
    "  response = tokenizer.decode(output)\n",
    "  res = response.split(\"<|start_header_id|>assistant<|end_header_id|>\")[2]\n",
    "  res = res.lstrip(\"\\n\")\n",
    "  print(res)\n",
    "\n",
    "  del messages[-1]\n",
    "\n",
    "## save result\n",
    "with open(\"sub_table.json\", \"w\") as f1:\n",
    "  json.dump(answers, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a table decomposer whose role is to extract only the necessary information from the given table and natural language query to create a summarized sub-table. Select the relevant rows and columns required to solve the problem and reconstruct them into a smaller table format. In table format, each cell starts with |cell| token and ends with |/cell| tokens. Cell's column and row information are enclosed by <col>, </col> and <row>, </row> tokens. Skip detailed information and ONLY answer the extracted information in table formatuser\n",
      "\n",
      "Query: during the 2012 year, did the equity awards in which the prescribed performance milestones were achieved exceed the equity award compensation expense for equity granted during the year?\n",
      "Table: <|cell|> <col> restricted stock and restricted stock units at beginning of year </col> <row> number of shares ( in thousands ) </row> <val> 407 </val> <|/cell|> <|cell|> <col> restricted stock and restricted stock units at beginning of year </col> <row> weighted average grant date fair value ( per share ) </row> <val> $ 9.84 </val> <|/cell|> <|cell|> <col> granted </col> <row> number of shares ( in thousands ) </row> <val> 607 </val> <|/cell|> <|cell|> <col> granted </col> <row> weighted average grant date fair value ( per share ) </row> <val> 18.13 </val> <|/cell|> <|cell|> <col> vested </col> <row> number of shares ( in thousands ) </row> <val> -134 ( 134 ) </val> <|/cell|> <|cell|> <col> vested </col> <row> weighted average grant date fair value ( per share ) </row> <val> 10.88 </val> <|/cell|> <|cell|> <col> forfeited </col> <row> number of shares ( in thousands ) </row> <val> -9 ( 9 ) </val> <|/cell|> <|cell|> <col> forfeited </col> <row> weighted average grant date fair value ( per share ) </row> <val> 13.72 </val> <|/cell|> <|cell|> <col> restricted stock and restricted stock units at end of year </col> <row> number of shares ( in thousands ) </row> <val> 871 </val> <|/cell|> <|cell|> <col> restricted stock and restricted stock units at end of year </col> <row> weighted average grant date fair value ( per share ) </row> <val> $ 15.76 </val> <|/cell|> \n",
      "Sub-Table:assistant\n",
      "\n",
      "|cell| <col> Restricted Stock and Restricted Stock Units </col> <row> 2012 </row> |</cell| \n",
      "|cell| <col> </col> <row> </row> <col> Number of Shares (in thousands) </col> <row> </row> |</cell| \n",
      "|cell| <col> Beginning of Year </col> <row> </row> |</cell| \n",
      "|cell| <col> </col> <row> </row> <val> 407 </val> |</cell| \n",
      "|cell| <col> End of Year </col> <row> </row> |</cell| \n",
      "|cell| <col> </col> <row> </row> <val> 871 </val> |</cell| \n",
      "|cell| <col> </col> <row> </row> <col> Weighted Average Grant Date Fair Value (per share) </col> <row> </row> |</cell| \n",
      "|cell| <col> Beginning of Year </col> <row> </row> |</cell| \n",
      "|cell| <col> </col> <row> </row> <val> $ 9.84 </val> |</cell| \n",
      "|cell| <col> End of Year </col> <row> </row> |</cell| \n",
      "|cell| <col> </col> <row> </row> <val> $ 15.76 </val> |</cell| \n",
      "|cell| <col> </col> <row> </row> <col> Equity Awards Compensation Expense </col> <row> </row> |</cell| \n",
      "|cell| <col> </col> <row> </row> <val> $ ( 607 * 18.13 ) - ( 134 * 10.88 ) + ( 9 * 13.72 ) </val> |</cell|\n"
     ]
    }
   ],
   "source": [
    "# generate sub table\n",
    "generate_kwargs = {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"max_length\": 4096,  # Adjust for total length\n",
    "    \"temperature\": 0.2,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id\n",
    "}\n",
    "\n",
    "output = base_model.generate(**generate_kwargs)[0]\n",
    "response = tokenizer.decode(output, skip_special_tokens=True)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.utils import gather_object\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,    \n",
    "    device_map={\"\": accelerator.process_index},\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id) \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "accelerator.wait_for_everyone()\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "input_ids = input_ids.to(\"cuda\")\n",
    "\n",
    "with accelerator.split_between_processes(messages) as prompts:\n",
    "  results = model.generate(\n",
    "    input_ids= input_ids,\n",
    "    max_length= 4096,  # Adjust for total length\n",
    "    temperature = 0.2,\n",
    "    pad_token_id= tokenizer.eos_token_id)[0]\n",
    "  res = tokenizer.decode(results, skip_special_tokens=True)\n",
    "\n",
    "results_gathered=gather_object(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|<cell>| <col> 2004 ( in thousands ) </col> <val> $ 31739 </val> |</cell>|\n",
      " |<cell>| <col> 2005 ( in thousands ) </col> <val> 14554 </val> |</cell>|\n",
      " |<cell>| <col> 2006 ( in thousands ) </col> <val> 18262 </val> |</cell>|\n",
      " |<cell>| <col> 2007 ( in thousands ) </col> <val> 18754 </val> |</cell>|\n",
      " |<cell>| <col> 2008 ( in thousands ) </col> <val> 22606 </val> |</cell\n",
      "\n",
      "|<cell>| <col> cash used in investing activities 2005 </col> <val> -2047 </val> |</cell>|\n",
      " |<cell>| <col> cash used in financing activities 2005 </col> <val> -752 </val> |</cell\n",
      "\n",
      "|<cell>| <col> december 31 ( in millions ) securities purchased under resale agreements ( a ) 2010 </col> <val> $ 222302 </val> |</cell>|\n",
      " |<cell>| <col> december 31 ( in millions ) securities borrowed ( b ) 2010 </col> <val> 123587 </val> |</cell>|\n",
      " |<cell>| <col> december 31 ( in millions ) securities sold under repurchase agreements ( c ) 2010 </col> <val> $ 262722 </val> |</cell>|\n",
      " |<cell>| <col> december 31 ( in millions ) securities loaned 2010 </col> <val> 10592 </val> |</cell>|\n",
      " |<cell>| <col> december 31 ( in millions ) securities purchased under resale agreements ( a ) 2009 </col> <val> $ 195328 </val> |</cell>|\n",
      " |<cell>| <col> december 31 ( in millions ) securities borrowed ( b ) 2009 </col> <val> 119630 </val> |</cell>|\n",
      " |<cell>| <col> december 31 ( in millions ) securities sold under repurchase agreements ( c ) 2009 </col> <val> $ 245692 </val> |</cell>|\n",
      " |<cell>| <col> december 31 ( in millions ) securities loaned 2009 </col> <val> 7835 </val> |</cell\n",
      "\n",
      "|<cell>| <col> for the years ended december 31, stock options 2011 </col> <val> $ 41.7 </val> |</cell>|\n",
      " |<cell>| <col> for the years ended december 31, stock options 2012 </col> <val> $ 32.4 </val> |</cell>|\n",
      " |<cell>| <col> for the years ended december 31, stock options 2013 </col> <val> $ 24.7 </val> |</cell\n",
      "\n",
      "|<cell>| <col> as of or for the year ended december 31 ( in millions ) afs investment securities ( average ) 2017 </col> <val> 219345 </val> |</cell>|\n",
      "|<cell>| <col> as of or for the year ended december 31 ( in millions ) afs investment securities ( period-end ) 2017 </col> <val> 200247 </val> |</cell>|\n",
      "|<cell>| <col> as of or for the year ended december 31 ( in millions ) investment securities portfolio ( average ) 2017 </col> <val> 267272 </val> |</cell\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"subtable_extract_0817.json\", \"r\") as file:\n",
    "  res = json.load(file)\n",
    "\n",
    "# print(len(res))\n",
    "for re in res[1005:1010]:\n",
    "  print(re)\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
