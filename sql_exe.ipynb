{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, PeftModel, get_peft_config, get_peft_model\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e70941085d4ce7a441120d54cc5974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call model/tokenizer\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    device_map='auto', \n",
    "    torch_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# print(base_model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call data\n",
    "with open(\"/home/broodling/finQA/post_schemas_0928.json\", \"r\") as f1:\n",
    "  posts = json.load(f1)\n",
    "\n",
    "with open(\"/home/broodling/finQA/pre_schemas_0928.json\", \"r\") as f2:\n",
    "  pres = json.load(f2)\n",
    "\n",
    "with open(\"/home/broodling/finQA/table_schemas_0928.json\", \"r\") as f3:\n",
    "  tables = json.load(f3)\n",
    "\n",
    "with open(\"/home/broodling/finQA/datasets/FinQA/dataset/train.json\", \"r\") as f4:\n",
    "  datas = json.load(f4)\n",
    "\n",
    "with open(\"/home/broodling/finQA/pre_values_0928.json\", \"r\") as f5:\n",
    "  preV = json.load(f5)\n",
    "\n",
    "with open(\"/home/broodling/finQA/table_values_0928.json\", \"r\") as f6:\n",
    "  tableV = json.load(f6)\n",
    "\n",
    "with open(\"/home/broodling/finQA/post_values_0928.json\", \"r\") as f7:\n",
    "  postV = json.load(f7)\n",
    "\n",
    "questions = []\n",
    "for ques in datas[:200]:\n",
    "  questions.append(ques['qa']['question'])\n",
    "\n",
    "\n",
    "with open(\"/home/broodling/finQA/text2sql_0929_200.json\", \"r\") as f:\n",
    "  sqls = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c =0\n",
    "for pre in preV:\n",
    "  if len(pre)>1:\n",
    "    print(pre)\n",
    "    c += 1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute sql query\n",
    "\n",
    "for idx in range(0, 3):\n",
    "  # db connect and create cursor \n",
    "  conn = sqlite3.connect(f\"fin200_{idx}.db\") \n",
    "  cur = conn.cursor()\n",
    "\n",
    "  # create table\n",
    "  cur.execute(pres[idx])\n",
    "  cur.execute(tables[idx])\n",
    "  cur.execute(posts[idx])\n",
    "\n",
    "  # Insert rows\n",
    "  for que1 in preV[idx]:\n",
    "    cur.execute(que1)\n",
    "  for que2 in tableV[idx]:\n",
    "    cur.execute(que2)\n",
    "  for que3 in postV[idx]:\n",
    "    cur.execute(que3)\n",
    "  conn.commit()\n",
    "\n",
    "  # sql execute\n",
    "  cur.execute(sqls[idx])\n",
    "  rows = cur.fetchall() # row\n",
    "\n",
    "  # Result 확인\n",
    "  print(idx, questions[idx])\n",
    "  print(sqls[idx])\n",
    "  for row in rows:\n",
    "    print(row)\n",
    "\n",
    "  conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt engineering\n",
    "sys_prompt = \"\"\"Given the sql table database information, sql query to execute and a question to solve, execute sql query and generate a correct answer to solve the given question. All information is represented in sql grammar format.\n",
    "Your goal is to:\n",
    "1. Understand structured data: Considering the given question to solve, understand given database table data, especially numerical values.\n",
    "2. Execute SQL query: Execute schema creation query and value inserting queries, then execute SQL query to solve the question. \n",
    "3. Amend to final answer: Executed results or sql query may be wrong, especially when sql needs complicated mathematical calculation. You should polish up or fix the results if needed to correctly answer the question. Final answer is usually NUMBER or short format(such as yes/no). \n",
    "\n",
    "Use the following format and ONLY generate the final answer:\n",
    "Question: \"Question\"\n",
    "Database: \"schema and inserted value information\"\n",
    "SQLQuery: \"SQL query to run\"\n",
    "FinalAnswer: \"Final answer based on SQL execution result\"\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Follow step by step sql reasoning. Given the database schemas, inserted values and a sql query, solve the financial question by executing SQL query. Based on executed results, correct the results if needed. The final answer is mostly number or short(yes/no) format. Do NOT print specific explanation, only give final answer.\n",
    "Schema: {schema}\n",
    "Values: {values}\\n\n",
    "Question: {ques}\n",
    "SQLQuery: {query}\n",
    "FinalAnswer: \"\"\"\n",
    "\n",
    "## few-shot example (BookSQL)\n",
    "sch = \"\"\"CREATE TABLE student (\n",
    "    student_id INTEGER,\n",
    "    last_name TEXT,\n",
    "    first_name TEXT,\n",
    "    age INTEGER,\n",
    "    sex TEXT,\n",
    "    major INTEGER,\n",
    "    advisor INTEGER, \n",
    "    city_code TEXT, \n",
    ");\n",
    "CREATE TABLE has_pet (\n",
    "    student_id INTEGER,\n",
    "    pet_id INTEGER,\n",
    ");\"\"\"\n",
    "vals =\"\"\"INSERT INTO student (student_id, last_name, first_name, age, sex, major, advisor, city_code) VALUES \n",
    "(1, 'Kim', 'Jin', 21, 'M', 101, 301, 'SEO'),\n",
    "(2, 'Lee', 'Hana', 22, 'F', 102, 302, 'BUS'),\n",
    "(3, 'Park', 'Minsoo', 20, 'M', 103, 303, 'ICN'),\n",
    "(4, 'Choi', 'Yuna', 23, 'F', 104, 304, 'DAE'),\n",
    "(5, 'Jung', 'Soojin', 22, 'F', 101, 305, 'GWA');\n",
    "\n",
    "INSERT INTO has_pet (student_id, pet_id) VALUES \n",
    "(1, 501),\n",
    "(3, 503),\n",
    "(5, 505);\n",
    "\"\"\"\n",
    "task = \"What is the average age for all students who do not own any pets?\"\n",
    "quer = \"SELECT avg(age) FROM student WHERE student_id NOT IN (SELECT T1.student_id FROM student AS T1 JOIN has_pet AS T2 ON T1.student_id = T2.student_id)\"\n",
    "user_prompt = template.format(schema=sch, values=vals, ques=task, query=quer)\n",
    "assistant_prompt = \"22.5\"\n",
    "\n",
    "messages =[\n",
    "  {\"role\": \"system\", \"content\": sys_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "  {\"role\": \"assistant\", \"content\": assistant_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = \"\"\n",
    "for que1 in preV[4]:\n",
    "  vals = vals + que1\n",
    "vals = vals + \"\\n\"\n",
    "for que2 in tableV[4]:\n",
    "  vals = vals + que2\n",
    "vals = vals + \"\\n\"\n",
    "for que3 in postV[4]:\n",
    "  vals = vals + que3\n",
    "\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the net chance in unrecognized tax benefits from 2011 to 2012 , ( in millions ) ?\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the growth rate in operating profit for aeronautics in 2011?\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what was the percentage increase in the operating lease obligations from 2009 to 2010\n",
      "-47.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for idx in tqdm(range(0,200)):\n",
    "  db_schema = pres[idx]+tables[idx]+posts[idx]\n",
    "  vals = \"\"\n",
    "  for que1 in preV[idx]:\n",
    "    vals = vals + que1\n",
    "  vals = vals + \"\\n\"\n",
    "  for que2 in tableV[idx]:\n",
    "    vals = vals + que2\n",
    "  vals = vals + \"\\n\"\n",
    "  for que3 in postV[idx]:\n",
    "    vals = vals + que3\n",
    "  user_prompt = template.format(schema=db_schema, values=vals, ques=questions[idx], query=sqls[idx])\n",
    "  dic = {\"role\": \"user\", \"content\": user_prompt}\n",
    "  messages.append(dic)\n",
    "  # print(dic[\"content\"])\n",
    "\n",
    "  input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "  input_ids = input_ids.to(base_model.device) \n",
    "\n",
    "  output = base_model.generate(input_ids=input_ids,\n",
    "                               max_length = 12500,\n",
    "                               temperature=0.2,\n",
    "                               pad_token_id = tokenizer.eos_token_id)[0]\n",
    "  \n",
    "  response = tokenizer.decode(output)\n",
    "  # print(response)\n",
    "  res = response.split(\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")[2]\n",
    "  res = res.split(\"<|eot_id|>\")[0]\n",
    "  res = res.lstrip(\"\\n\")\n",
    "  # print(res)\n",
    "\n",
    "  answers.append(res)\n",
    "  del messages[-1]\n",
    "\n",
    "\n",
    "# save results\n",
    "with open(\"final_answer_0929_200.json\", \"w\") as file:\n",
    "  json.dump(answers, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
